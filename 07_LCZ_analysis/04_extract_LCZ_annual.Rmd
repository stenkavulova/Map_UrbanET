---
title: "Extract annual (LCZ)"
author: "Stenka Vulova"
date: "17 Feb. 2022"
output: html_document
---

I am now using the Generator LCZ (training data from Fenner 2017), with the Gaussian filter. 

# Libraries 

```{r libraries, include = FALSE }

library(sp)
library(raster)
library(rgdal)
library(lubridate)
library(maptools)
library(ggplot2)
library(tidyr)
library(plyr)
library(dplyr)
library(RColorBrewer)
library(reshape2)
library(scales)
library(readr)
library(rgeos)

library(terra)

library(grid)
library(spatstat)
library(sf)

library(zoo)
library(tictoc) # benchmarking

library(pbapply)

library(spatialEco) # for weighted_footprint function 

library(caret)
library(doSNOW) # do training in parallel
library(doParallel) 
library(randomForest)

#devtools::install_github("AlbyDR/rSCOPE")

#library(rSCOPE)

library(exactextractr)

```


# Load annual ET 

## ET 

```{r load ET }

ETannual_2019 = raster::raster("D:/Stenka_UWI/Topic_3/05_RESULTS/20220128_monthly_ET_maps/2019_annual_sum/ETannual_2019.tif")

raster::plot(ETannual_2019, col = colorRampPalette(c("dark red", "red3", "orange1", 'lightgoldenrod1', "seagreen1", "dodgerblue4", "blue4"))(255))

raster::crs(ETannual_2019)

```

# LCZ 

```{r LCZ shapefile }

LCZ = rgdal::readOGR(dsn = "D:/Stenka_UWI/Topic_3/04_PROCESSED_DATA/20220217_LCZ_shape_Gene", layer = "LCZ_Berlin",
                    verbose = TRUE)

# 13 features 

#### convert to sf ####

# convert to sf

LCZ_sf = sf::st_as_sf(LCZ)

#### old crop ###

## Previously I cropped here. 

#LCZ = terra::vect(LCZ) # convert to terra vect 

#terra::plot(LCZ)

#LCZ
#ETannual_2019

# need to crop

#LCZ_Berlin = terra::crop(x = LCZ, y = ETannual_2019)

#terra::plot(LCZ_Berlin)

# save it 

#terra::writeVector(x = LCZ_Berlin, "D:/Stenka_UWI/Topic_3/04_PROCESSED_DATA/20220217_LCZ_shape_Gene/LCZ_Berlin.shp",
#                   filetype = "ESRI Shapefile")

```


# Extract 

```{r xtract }

tic("extract")

ex_LCZ = exact_extract(x = ETannual_2019, y = LCZ_sf)

toc()

tic.clearlog()

# extract: 15.31 sec elapsed


glimpse(ex_LCZ)
# Large list (13 elements)

```

# Explore 

```{r explore }

ex_LCZ_1 = ex_LCZ[[1]]

glimpse(ex_LCZ_1)

ex_LCZ_1$LCZ = LCZ_sf$LCZ_Gen_Fe[[1]]

```

# Function to add LCZ column 

Function to add LCZ column 

```{r function add column }

# ex_LCZ = list of extracted values for Local Climate Zones
# LCZ_sf: the sf polygon dataframe used to extract
# numba: which dataframe in the list of (13) dataframes

add_LCZ_column = function(ex_LCZ, LCZ_sf, numba) {
  
  ex_LCZ_new = ex_LCZ[[numba]]
  ex_LCZ_new$LCZ = LCZ_sf$LCZ_Gen_Fe[[numba]]
  return(ex_LCZ_new)
  
}

```

## test once 

```{r Test once }

ex_LCZ_2 = add_LCZ_column(ex_LCZ = ex_LCZ, LCZ_sf = LCZ_sf, numba = 2)

glimpse(ex_LCZ_2)

```
## Apply to all

```{r Apply to all }
tic("add_LCZ_column")

l_LCZ_dfs = pbapply::pblapply(1:13, function(i)
  
  add_LCZ_column(ex_LCZ = ex_LCZ, LCZ_sf = LCZ_sf, numba = i)
  
)

toc()

tic.clearlog()

# add_LCZ_column: 0.39 sec elapsed


```
# Join dfs

```{r join dfs }

# join all

LCZ_annual_ex = plyr::join_all(dfs = l_LCZ_dfs, type = "full")

# probably should append next time .... this was not efficient

glimpse(LCZ_annual_ex)

# Rows: 28,829,322
unique(LCZ_annual_ex$LCZ)
#  "0"  "2"  "4"  "5"  "6"  "8"  "9"  "11" "12" "13" "14" "16" "17"

# save 
#save(LCZ_annual_ex, file = "D:/Stenka_UWI/Topic_3/05_RESULTS/20220218_ex_LCZ_Gen/Annual/LCZ_annual_ex.RData")

```

